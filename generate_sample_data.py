import pandas as pd
import random
from faker import Faker
from datetime import datetime, timedelta

fake = Faker("vi_VN")

# C√°c field ƒë∆∞·ª£c d√πng chung gi·ªØa nhi·ªÅu b·∫£ng
COMMON_FIELDS = ["Date", "Employee_Name", "product_name"]

def random_date(start_date, end_date):
    return start_date + timedelta(days=random.randint(0, (end_date - start_date).days))

def random_code(length=6):
    return ''.join(random.choices("ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789", k=random.randint(5, length)))

def generate_common_row():
    return {
        "Date": random_date(datetime(2024, 1, 1), datetime(2024, 4, 10)).strftime("%Y-%m-%d"),
        "Employee_Name": fake.name(),
        "product_name": random.choice(["ƒë√®n LED tr√≤n", "ƒë√®n b√†n h·ªçc", "ƒë√®n LED √¢m tr·∫ßn", "ƒë√®n c·∫£m ·ª©ng"])
    }

def generate_full_row(field_names, common_data):
    row = {}
    for field in field_names:
        f_lower = field.lower()

        # ∆Øu ti√™n d√πng d·ªØ li·ªáu chung
        if field in common_data:
            row[field] = common_data[field]
        elif "department" in f_lower or "ph√≤ng" in f_lower:
            row[field] = random.choice(["ph√≤ng kinh doanh", "ph√≤ng k·ªπ thu·∫≠t", "ph√≤ng nh√¢n s·ª±", "ph√≤ng R&D"])
        elif "unit" in f_lower or "ƒë∆°n v·ªã" in f_lower:
            row[field] = random.choice(["c√¥ng ty TNHH ABC", "c√¥ng ty c·ªï ph·∫ßn XYZ", "c√¥ng ty TNHH M·ªôt Th√†nh Vi√™n 123"])
        elif "province" in f_lower or "t·ªânh" in f_lower:
            row[field] = random.choice(["H√† N·ªôi", "TP H·ªì Ch√≠ Minh", "ƒê√† N·∫µng", "C·∫ßn Th∆°"])
        elif "region" in f_lower or "v√πng" in f_lower:
            row[field] = random.choice(["mi·ªÅn B·∫Øc", "mi·ªÅn Trung", "mi·ªÅn Nam"])
        elif "code" in f_lower:
            row[field] = random_code()
        elif "s·ªë l∆∞·ª£ng" in f_lower:
            row[field] = random.randint(1, 100)
        elif "s·ªë" in f_lower:
            row[field] = random.randint(1, 1000)
        else:
            row[field] = fake.word()
    return row

def generate_data_with_consistency(field_names_dict, row_count=2000):
    data = {table: [] for table in field_names_dict}

    for _ in range(row_count):
        common_row = generate_common_row()
        for table, fields in field_names_dict.items():
            full_row = generate_full_row(fields, common_row)
            data[table].append(full_row)

    return {table: pd.DataFrame(rows) for table, rows in data.items()}

# üéØ Khai b√°o c√°c fields cho t·ª´ng b·∫£ng (l·∫•y t·ª´ Excel n·∫øu mu·ªën)
fields_salein_class = ["Date", "Employee_Name", "Department", "item_code", "product_name", "S·ªë l∆∞·ª£ng"]
fields_salein_thuc_xuat = ["Date", "Employee_Name", "unit_code", "product_name", "S·ªë l∆∞·ª£ng xu·∫•t", "province"]
fields_kpi_thuc_xuat = ["Date", "Employee_Name", "KPI_code", "region", "product_name", "S·ªë KPI"]

# T·∫°o d·ªØ li·ªáu
field_map = {
    "salein_class": fields_salein_class,
    "salein_thuc_xuat": fields_salein_thuc_xuat,
    "kpi_thuc_xuat": fields_kpi_thuc_xuat
}

df_map = generate_data_with_consistency(field_map)

# Xu·∫•t ra file CSV
for table_name, df in df_map.items():
    df.to_csv(f"{table_name}.csv", index=False, encoding='utf-8-sig')

print("‚úÖ Ho√†n t·∫•t sinh d·ªØ li·ªáu! C√°c file CSV ƒë√£ ƒë∆∞·ª£c t·∫°o.")
